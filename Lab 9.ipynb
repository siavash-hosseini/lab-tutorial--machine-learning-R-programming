{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1SW_zO-RgDzRoIjJGPl1kJPTqY4cTSlrf","timestamp":1638131726618}]},"kernelspec":{"name":"ir","display_name":"R"},"language_info":{"name":"R"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xldxP1r_qjn0"},"source":["# Lab 9: Text Analysis"]},{"cell_type":"markdown","metadata":{"id":"dF-sU2IFAfUb"},"source":["In this lab we primarily focus on text analysis approaches. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"2nhnOPwEEuHr"},"source":["# Installing and Loading Packages"]},{"cell_type":"markdown","metadata":{"id":"W96qrqX5FRV_"},"source":["Installing all packages"]},{"cell_type":"code","metadata":{"id":"DoYzezdCExbq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669823484327,"user_tz":300,"elapsed":235794,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"14501132-a943-4ab4-b168-fd342e0bcf09"},"source":["install.packages('quanteda') # Takes arabout 2min"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","also installing the dependencies ‘ISOcodes’, ‘fastmatch’, ‘Rcpp’, ‘RcppParallel’, ‘SnowballC’, ‘stopwords’, ‘RcppArmadillo’\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"y5ykhAxOcCds","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669823828871,"user_tz":300,"elapsed":344566,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"71483bc5-638e-4d03-e603-1f2f87a6cca0"},"source":["install.packages(\"quanteda.textmodels\")  # Takes > 4 min"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","also installing the dependencies ‘iterators’, ‘foreach’, ‘shape’, ‘RcppEigen’, ‘glmnet’, ‘LiblineaR’, ‘RSpectra’, ‘SparseM’\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"-fHLPDPevP_V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669823919049,"user_tz":300,"elapsed":90227,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"259787cb-b816-4ce8-e1f3-f6204bd41a89"},"source":["install.packages('quanteda.textstats') # Takes > 1 min"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","also installing the dependencies ‘nsyllable’, ‘proxyC’\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"zP8M2ryonzBx"},"source":["system(\"apt-get install libgsl0-dev\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtdPl8DOnzBy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669823984776,"user_tz":300,"elapsed":54951,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"f5be0bc9-60ea-40ad-bc8e-a8b2a5db9d85"},"source":["install.packages('topicmodels') # Takes less than 1min"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","also installing the dependencies ‘NLP’, ‘BH’, ‘modeltools’, ‘slam’, ‘tm’\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"exCRYWF-Fd4v"},"source":["library(stringi)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M-r4vFIEI3I_"},"source":["##  Task 1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"2xHW4r-gEraS","executionInfo":{"status":"ok","timestamp":1669824126742,"user_tz":300,"elapsed":177,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"01fce10f-6ade-4759-ca9d-1918b7bb241e"},"source":["x <- c(\"The first string\", ' The <font size=\"6\">second string</font>') \n","x"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<style>\n",".list-inline {list-style: none; margin:0; padding: 0}\n",".list-inline>li {display: inline-block}\n",".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n","</style>\n","<ol class=list-inline><li>'The first string'</li><li>' The &lt;font size=\"6\"&gt;second string&lt;/font&gt;'</li></ol>\n"],"text/markdown":"1. 'The first string'\n2. ' The &lt;font size=\"6\"&gt;second string&lt;/font&gt;'\n\n\n","text/latex":"\\begin{enumerate*}\n\\item 'The first string'\n\\item ' The <font size=\"6\">second string</font>'\n\\end{enumerate*}\n","text/plain":["[1] \"The first string\"                          \n","[2] \" The <font size=\\\"6\\\">second string</font>\""]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"-x5_UZuyGMTQ"},"source":["**Step 1**\n","\n","Use the `stri_replace_all_regex` function to remove all HTML tags from the given string. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"ercz-y1oNn_w","executionInfo":{"status":"ok","timestamp":1669824221992,"user_tz":300,"elapsed":195,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"3f771b78-1213-47dc-a2a8-5b627acec5b0"},"source":["x <- stri_replace_all_regex(# Write your code here)\n","x"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<style>\n",".list-inline {list-style: none; margin:0; padding: 0}\n",".list-inline>li {display: inline-block}\n",".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n","</style>\n","<ol class=list-inline><li>'The first string'</li><li>' The second string'</li></ol>\n"],"text/markdown":"1. 'The first string'\n2. ' The second string'\n\n\n","text/latex":"\\begin{enumerate*}\n\\item 'The first string'\n\\item ' The second string'\n\\end{enumerate*}\n","text/plain":["[1] \"The first string\"   \" The second string\""]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"fMiabAxfIRx_"},"source":["**Step 2**\n","\n","Transform the string to lower case. Use the auto-complete to find the proper command, starting with `stri_trans_tolower`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"EtFiJ06cRw3U","executionInfo":{"status":"ok","timestamp":1669824555441,"user_tz":300,"elapsed":194,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"3fd18077-7fd0-4794-86c4-6fd933846d93"},"source":["x <- # Write your code here\n","x"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<style>\n",".list-inline {list-style: none; margin:0; padding: 0}\n",".list-inline>li {display: inline-block}\n",".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n","</style>\n","<ol class=list-inline><li>'the first string'</li><li>' the second string'</li></ol>\n"],"text/markdown":"1. 'the first string'\n2. ' the second string'\n\n\n","text/latex":"\\begin{enumerate*}\n\\item 'the first string'\n\\item ' the second string'\n\\end{enumerate*}\n","text/plain":["[1] \"the first string\"   \" the second string\""]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"SxrNxGtuI6i6"},"source":["## Tokenization - Task 2"]},{"cell_type":"markdown","metadata":{"id":"bFl9__HtJL5n"},"source":["**Step 1**\n","\n","Using the `quanteda` package, perform tokenization on the string below to produce unigrams. Look up the `tokens` function."]},{"cell_type":"code","metadata":{"id":"LXKfJroaJxHG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669824605340,"user_tz":300,"elapsed":2183,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"abb10d2f-fd92-46ef-9c24-85c2839134c6"},"source":["# Loading Package\n","library(quanteda)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Package version: 3.2.3\n","Unicode version: 10.0\n","ICU version: 60.2\n","\n","Parallel computing: 2 of 2 threads used.\n","\n","See https://quanteda.io for tutorials and examples.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"-bXTWO_kI79U","executionInfo":{"status":"ok","timestamp":1669824626065,"user_tz":300,"elapsed":207,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"f070c85d-aeb9-4e23-dfb8-b8a5a7a25fbc"},"source":["text <- \"Focus During An example of Preprocessing Techniques\" \n","\n","\n","toks <- # Write your code here\n","toks \n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Tokens consisting of 1 document.\n","text1 :\n","[1] \"Focus\"         \"During\"        \"An\"            \"example\"      \n","[5] \"of\"            \"Preprocessing\" \"Techniques\"   \n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"oa05OUqOL7XW"},"source":["## Nomalization - Task 3"]},{"cell_type":"markdown","metadata":{"id":"RsH38Hf8MiyC"},"source":["**Step 1 - Lower Case**\n","\n","Transform all tokens to lower case. Use the auto-complete to find the proper command, starting with `tokens_tolower`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"Nhm1PgS_TNCN","executionInfo":{"status":"ok","timestamp":1669824653016,"user_tz":300,"elapsed":341,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"483b16bc-c642-4bb7-d076-d5f09cdfb38b"},"source":["toks <-# Write your code here\n","toks"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Tokens consisting of 1 document.\n","text1 :\n","[1] \"focus\"         \"during\"        \"an\"            \"example\"      \n","[5] \"of\"            \"preprocessing\" \"techniques\"   \n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"bj7e0pWuM9x7"},"source":["**Step 2 - Stemmer**\n","\n","Apply stemmer to tokens. Use the auto-complete to find the proper command, starting with `tokens_wordstem`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"gLDQgwu2Tbpv","executionInfo":{"status":"ok","timestamp":1669824698066,"user_tz":300,"elapsed":357,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"2bf89c6d-9991-4500-f899-2613b0851b32"},"source":["toks <- # Write your code here\n","toks"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Tokens consisting of 1 document.\n","text1 :\n","[1] \"focus\"      \"dure\"       \"an\"         \"exampl\"     \"of\"        \n","[6] \"preprocess\" \"techniqu\"  \n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"qVIOrrwFNhwp"},"source":["## Removing Stop Words - Task 4"]},{"cell_type":"markdown","metadata":{"id":"47f2iN-bNmv2"},"source":["**Step 1 - Loading Stop Words**\n","\n","Load the `stopwords` for the `\"english\"` language."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156},"id":"rAsHZQVbUB0i","executionInfo":{"status":"ok","timestamp":1669825102204,"user_tz":300,"elapsed":249,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"ae241472-427c-4c9e-d3c8-b468abfceee1"},"source":["\n","sw <- stopwords(\"en\")\n","sw"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<style>\n",".list-inline {list-style: none; margin:0; padding: 0}\n",".list-inline>li {display: inline-block}\n",".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n","</style>\n","<ol class=list-inline><li>'i'</li><li>'me'</li><li>'my'</li><li>'myself'</li><li>'we'</li><li>'our'</li><li>'ours'</li><li>'ourselves'</li><li>'you'</li><li>'your'</li><li>'yours'</li><li>'yourself'</li><li>'yourselves'</li><li>'he'</li><li>'him'</li><li>'his'</li><li>'himself'</li><li>'she'</li><li>'her'</li><li>'hers'</li><li>'herself'</li><li>'it'</li><li>'its'</li><li>'itself'</li><li>'they'</li><li>'them'</li><li>'their'</li><li>'theirs'</li><li>'themselves'</li><li>'what'</li><li>'which'</li><li>'who'</li><li>'whom'</li><li>'this'</li><li>'that'</li><li>'these'</li><li>'those'</li><li>'am'</li><li>'is'</li><li>'are'</li><li>'was'</li><li>'were'</li><li>'be'</li><li>'been'</li><li>'being'</li><li>'have'</li><li>'has'</li><li>'had'</li><li>'having'</li><li>'do'</li><li>'does'</li><li>'did'</li><li>'doing'</li><li>'would'</li><li>'should'</li><li>'could'</li><li>'ought'</li><li>'i\\'m'</li><li>'you\\'re'</li><li>'he\\'s'</li><li>'she\\'s'</li><li>'it\\'s'</li><li>'we\\'re'</li><li>'they\\'re'</li><li>'i\\'ve'</li><li>'you\\'ve'</li><li>'we\\'ve'</li><li>'they\\'ve'</li><li>'i\\'d'</li><li>'you\\'d'</li><li>'he\\'d'</li><li>'she\\'d'</li><li>'we\\'d'</li><li>'they\\'d'</li><li>'i\\'ll'</li><li>'you\\'ll'</li><li>'he\\'ll'</li><li>'she\\'ll'</li><li>'we\\'ll'</li><li>'they\\'ll'</li><li>'isn\\'t'</li><li>'aren\\'t'</li><li>'wasn\\'t'</li><li>'weren\\'t'</li><li>'hasn\\'t'</li><li>'haven\\'t'</li><li>'hadn\\'t'</li><li>'doesn\\'t'</li><li>'don\\'t'</li><li>'didn\\'t'</li><li>'won\\'t'</li><li>'wouldn\\'t'</li><li>'shan\\'t'</li><li>'shouldn\\'t'</li><li>'can\\'t'</li><li>'cannot'</li><li>'couldn\\'t'</li><li>'mustn\\'t'</li><li>'let\\'s'</li><li>'that\\'s'</li><li>'who\\'s'</li><li>'what\\'s'</li><li>'here\\'s'</li><li>'there\\'s'</li><li>'when\\'s'</li><li>'where\\'s'</li><li>'why\\'s'</li><li>'how\\'s'</li><li>'a'</li><li>'an'</li><li>'the'</li><li>'and'</li><li>'but'</li><li>'if'</li><li>'or'</li><li>'because'</li><li>'as'</li><li>'until'</li><li>'while'</li><li>'of'</li><li>'at'</li><li>'by'</li><li>'for'</li><li>'with'</li><li>'about'</li><li>'against'</li><li>'between'</li><li>'into'</li><li>'through'</li><li>'during'</li><li>'before'</li><li>'after'</li><li>'above'</li><li>'below'</li><li>'to'</li><li>'from'</li><li>'up'</li><li>'down'</li><li>'in'</li><li>'out'</li><li>'on'</li><li>'off'</li><li>'over'</li><li>'under'</li><li>'again'</li><li>'further'</li><li>'then'</li><li>'once'</li><li>'here'</li><li>'there'</li><li>'when'</li><li>'where'</li><li>'why'</li><li>'how'</li><li>'all'</li><li>'any'</li><li>'both'</li><li>'each'</li><li>'few'</li><li>'more'</li><li>'most'</li><li>'other'</li><li>'some'</li><li>'such'</li><li>'no'</li><li>'nor'</li><li>'not'</li><li>'only'</li><li>'own'</li><li>'same'</li><li>'so'</li><li>'than'</li><li>'too'</li><li>'very'</li><li>'will'</li></ol>\n"],"text/markdown":"1. 'i'\n2. 'me'\n3. 'my'\n4. 'myself'\n5. 'we'\n6. 'our'\n7. 'ours'\n8. 'ourselves'\n9. 'you'\n10. 'your'\n11. 'yours'\n12. 'yourself'\n13. 'yourselves'\n14. 'he'\n15. 'him'\n16. 'his'\n17. 'himself'\n18. 'she'\n19. 'her'\n20. 'hers'\n21. 'herself'\n22. 'it'\n23. 'its'\n24. 'itself'\n25. 'they'\n26. 'them'\n27. 'their'\n28. 'theirs'\n29. 'themselves'\n30. 'what'\n31. 'which'\n32. 'who'\n33. 'whom'\n34. 'this'\n35. 'that'\n36. 'these'\n37. 'those'\n38. 'am'\n39. 'is'\n40. 'are'\n41. 'was'\n42. 'were'\n43. 'be'\n44. 'been'\n45. 'being'\n46. 'have'\n47. 'has'\n48. 'had'\n49. 'having'\n50. 'do'\n51. 'does'\n52. 'did'\n53. 'doing'\n54. 'would'\n55. 'should'\n56. 'could'\n57. 'ought'\n58. 'i\\'m'\n59. 'you\\'re'\n60. 'he\\'s'\n61. 'she\\'s'\n62. 'it\\'s'\n63. 'we\\'re'\n64. 'they\\'re'\n65. 'i\\'ve'\n66. 'you\\'ve'\n67. 'we\\'ve'\n68. 'they\\'ve'\n69. 'i\\'d'\n70. 'you\\'d'\n71. 'he\\'d'\n72. 'she\\'d'\n73. 'we\\'d'\n74. 'they\\'d'\n75. 'i\\'ll'\n76. 'you\\'ll'\n77. 'he\\'ll'\n78. 'she\\'ll'\n79. 'we\\'ll'\n80. 'they\\'ll'\n81. 'isn\\'t'\n82. 'aren\\'t'\n83. 'wasn\\'t'\n84. 'weren\\'t'\n85. 'hasn\\'t'\n86. 'haven\\'t'\n87. 'hadn\\'t'\n88. 'doesn\\'t'\n89. 'don\\'t'\n90. 'didn\\'t'\n91. 'won\\'t'\n92. 'wouldn\\'t'\n93. 'shan\\'t'\n94. 'shouldn\\'t'\n95. 'can\\'t'\n96. 'cannot'\n97. 'couldn\\'t'\n98. 'mustn\\'t'\n99. 'let\\'s'\n100. 'that\\'s'\n101. 'who\\'s'\n102. 'what\\'s'\n103. 'here\\'s'\n104. 'there\\'s'\n105. 'when\\'s'\n106. 'where\\'s'\n107. 'why\\'s'\n108. 'how\\'s'\n109. 'a'\n110. 'an'\n111. 'the'\n112. 'and'\n113. 'but'\n114. 'if'\n115. 'or'\n116. 'because'\n117. 'as'\n118. 'until'\n119. 'while'\n120. 'of'\n121. 'at'\n122. 'by'\n123. 'for'\n124. 'with'\n125. 'about'\n126. 'against'\n127. 'between'\n128. 'into'\n129. 'through'\n130. 'during'\n131. 'before'\n132. 'after'\n133. 'above'\n134. 'below'\n135. 'to'\n136. 'from'\n137. 'up'\n138. 'down'\n139. 'in'\n140. 'out'\n141. 'on'\n142. 'off'\n143. 'over'\n144. 'under'\n145. 'again'\n146. 'further'\n147. 'then'\n148. 'once'\n149. 'here'\n150. 'there'\n151. 'when'\n152. 'where'\n153. 'why'\n154. 'how'\n155. 'all'\n156. 'any'\n157. 'both'\n158. 'each'\n159. 'few'\n160. 'more'\n161. 'most'\n162. 'other'\n163. 'some'\n164. 'such'\n165. 'no'\n166. 'nor'\n167. 'not'\n168. 'only'\n169. 'own'\n170. 'same'\n171. 'so'\n172. 'than'\n173. 'too'\n174. 'very'\n175. 'will'\n\n\n","text/latex":"\\begin{enumerate*}\n\\item 'i'\n\\item 'me'\n\\item 'my'\n\\item 'myself'\n\\item 'we'\n\\item 'our'\n\\item 'ours'\n\\item 'ourselves'\n\\item 'you'\n\\item 'your'\n\\item 'yours'\n\\item 'yourself'\n\\item 'yourselves'\n\\item 'he'\n\\item 'him'\n\\item 'his'\n\\item 'himself'\n\\item 'she'\n\\item 'her'\n\\item 'hers'\n\\item 'herself'\n\\item 'it'\n\\item 'its'\n\\item 'itself'\n\\item 'they'\n\\item 'them'\n\\item 'their'\n\\item 'theirs'\n\\item 'themselves'\n\\item 'what'\n\\item 'which'\n\\item 'who'\n\\item 'whom'\n\\item 'this'\n\\item 'that'\n\\item 'these'\n\\item 'those'\n\\item 'am'\n\\item 'is'\n\\item 'are'\n\\item 'was'\n\\item 'were'\n\\item 'be'\n\\item 'been'\n\\item 'being'\n\\item 'have'\n\\item 'has'\n\\item 'had'\n\\item 'having'\n\\item 'do'\n\\item 'does'\n\\item 'did'\n\\item 'doing'\n\\item 'would'\n\\item 'should'\n\\item 'could'\n\\item 'ought'\n\\item 'i\\textbackslash{}'m'\n\\item 'you\\textbackslash{}'re'\n\\item 'he\\textbackslash{}'s'\n\\item 'she\\textbackslash{}'s'\n\\item 'it\\textbackslash{}'s'\n\\item 'we\\textbackslash{}'re'\n\\item 'they\\textbackslash{}'re'\n\\item 'i\\textbackslash{}'ve'\n\\item 'you\\textbackslash{}'ve'\n\\item 'we\\textbackslash{}'ve'\n\\item 'they\\textbackslash{}'ve'\n\\item 'i\\textbackslash{}'d'\n\\item 'you\\textbackslash{}'d'\n\\item 'he\\textbackslash{}'d'\n\\item 'she\\textbackslash{}'d'\n\\item 'we\\textbackslash{}'d'\n\\item 'they\\textbackslash{}'d'\n\\item 'i\\textbackslash{}'ll'\n\\item 'you\\textbackslash{}'ll'\n\\item 'he\\textbackslash{}'ll'\n\\item 'she\\textbackslash{}'ll'\n\\item 'we\\textbackslash{}'ll'\n\\item 'they\\textbackslash{}'ll'\n\\item 'isn\\textbackslash{}'t'\n\\item 'aren\\textbackslash{}'t'\n\\item 'wasn\\textbackslash{}'t'\n\\item 'weren\\textbackslash{}'t'\n\\item 'hasn\\textbackslash{}'t'\n\\item 'haven\\textbackslash{}'t'\n\\item 'hadn\\textbackslash{}'t'\n\\item 'doesn\\textbackslash{}'t'\n\\item 'don\\textbackslash{}'t'\n\\item 'didn\\textbackslash{}'t'\n\\item 'won\\textbackslash{}'t'\n\\item 'wouldn\\textbackslash{}'t'\n\\item 'shan\\textbackslash{}'t'\n\\item 'shouldn\\textbackslash{}'t'\n\\item 'can\\textbackslash{}'t'\n\\item 'cannot'\n\\item 'couldn\\textbackslash{}'t'\n\\item 'mustn\\textbackslash{}'t'\n\\item 'let\\textbackslash{}'s'\n\\item 'that\\textbackslash{}'s'\n\\item 'who\\textbackslash{}'s'\n\\item 'what\\textbackslash{}'s'\n\\item 'here\\textbackslash{}'s'\n\\item 'there\\textbackslash{}'s'\n\\item 'when\\textbackslash{}'s'\n\\item 'where\\textbackslash{}'s'\n\\item 'why\\textbackslash{}'s'\n\\item 'how\\textbackslash{}'s'\n\\item 'a'\n\\item 'an'\n\\item 'the'\n\\item 'and'\n\\item 'but'\n\\item 'if'\n\\item 'or'\n\\item 'because'\n\\item 'as'\n\\item 'until'\n\\item 'while'\n\\item 'of'\n\\item 'at'\n\\item 'by'\n\\item 'for'\n\\item 'with'\n\\item 'about'\n\\item 'against'\n\\item 'between'\n\\item 'into'\n\\item 'through'\n\\item 'during'\n\\item 'before'\n\\item 'after'\n\\item 'above'\n\\item 'below'\n\\item 'to'\n\\item 'from'\n\\item 'up'\n\\item 'down'\n\\item 'in'\n\\item 'out'\n\\item 'on'\n\\item 'off'\n\\item 'over'\n\\item 'under'\n\\item 'again'\n\\item 'further'\n\\item 'then'\n\\item 'once'\n\\item 'here'\n\\item 'there'\n\\item 'when'\n\\item 'where'\n\\item 'why'\n\\item 'how'\n\\item 'all'\n\\item 'any'\n\\item 'both'\n\\item 'each'\n\\item 'few'\n\\item 'more'\n\\item 'most'\n\\item 'other'\n\\item 'some'\n\\item 'such'\n\\item 'no'\n\\item 'nor'\n\\item 'not'\n\\item 'only'\n\\item 'own'\n\\item 'same'\n\\item 'so'\n\\item 'than'\n\\item 'too'\n\\item 'very'\n\\item 'will'\n\\end{enumerate*}\n","text/plain":["  [1] \"i\"          \"me\"         \"my\"         \"myself\"     \"we\"        \n","  [6] \"our\"        \"ours\"       \"ourselves\"  \"you\"        \"your\"      \n"," [11] \"yours\"      \"yourself\"   \"yourselves\" \"he\"         \"him\"       \n"," [16] \"his\"        \"himself\"    \"she\"        \"her\"        \"hers\"      \n"," [21] \"herself\"    \"it\"         \"its\"        \"itself\"     \"they\"      \n"," [26] \"them\"       \"their\"      \"theirs\"     \"themselves\" \"what\"      \n"," [31] \"which\"      \"who\"        \"whom\"       \"this\"       \"that\"      \n"," [36] \"these\"      \"those\"      \"am\"         \"is\"         \"are\"       \n"," [41] \"was\"        \"were\"       \"be\"         \"been\"       \"being\"     \n"," [46] \"have\"       \"has\"        \"had\"        \"having\"     \"do\"        \n"," [51] \"does\"       \"did\"        \"doing\"      \"would\"      \"should\"    \n"," [56] \"could\"      \"ought\"      \"i'm\"        \"you're\"     \"he's\"      \n"," [61] \"she's\"      \"it's\"       \"we're\"      \"they're\"    \"i've\"      \n"," [66] \"you've\"     \"we've\"      \"they've\"    \"i'd\"        \"you'd\"     \n"," [71] \"he'd\"       \"she'd\"      \"we'd\"       \"they'd\"     \"i'll\"      \n"," [76] \"you'll\"     \"he'll\"      \"she'll\"     \"we'll\"      \"they'll\"   \n"," [81] \"isn't\"      \"aren't\"     \"wasn't\"     \"weren't\"    \"hasn't\"    \n"," [86] \"haven't\"    \"hadn't\"     \"doesn't\"    \"don't\"      \"didn't\"    \n"," [91] \"won't\"      \"wouldn't\"   \"shan't\"     \"shouldn't\"  \"can't\"     \n"," [96] \"cannot\"     \"couldn't\"   \"mustn't\"    \"let's\"      \"that's\"    \n","[101] \"who's\"      \"what's\"     \"here's\"     \"there's\"    \"when's\"    \n","[106] \"where's\"    \"why's\"      \"how's\"      \"a\"          \"an\"        \n","[111] \"the\"        \"and\"        \"but\"        \"if\"         \"or\"        \n","[116] \"because\"    \"as\"         \"until\"      \"while\"      \"of\"        \n","[121] \"at\"         \"by\"         \"for\"        \"with\"       \"about\"     \n","[126] \"against\"    \"between\"    \"into\"       \"through\"    \"during\"    \n","[131] \"before\"     \"after\"      \"above\"      \"below\"      \"to\"        \n","[136] \"from\"       \"up\"         \"down\"       \"in\"         \"out\"       \n","[141] \"on\"         \"off\"        \"over\"       \"under\"      \"again\"     \n","[146] \"further\"    \"then\"       \"once\"       \"here\"       \"there\"     \n","[151] \"when\"       \"where\"      \"why\"        \"how\"        \"all\"       \n","[156] \"any\"        \"both\"       \"each\"       \"few\"        \"more\"      \n","[161] \"most\"       \"other\"      \"some\"       \"such\"       \"no\"        \n","[166] \"nor\"        \"not\"        \"only\"       \"own\"        \"same\"      \n","[171] \"so\"         \"than\"       \"too\"        \"very\"       \"will\"      "]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Wqnz4obIOCZf"},"source":["**Step 2 - Removing Stop Works**\n","\n","Remove stopwords"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"kPf7uHOUVI1V","executionInfo":{"status":"ok","timestamp":1669825127313,"user_tz":300,"elapsed":226,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"a14780d0-762f-4bff-d1a0-b81f4db28c45"},"source":["\n","toks <- tokens_remove(# Write your code here)\n","toks "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Tokens consisting of 1 document.\n","text1 :\n","[1] \"focus\"      \"dure\"       \"exampl\"     \"preprocess\" \"techniqu\"  \n"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"tHImBS2eRVH9"},"source":["## Document-Term Matrix (DTM) - Task 6"]},{"cell_type":"markdown","source":["A document-term matrix is a mathematical matrix that describes the frequency of terms that occur in a collection of documents"],"metadata":{"id":"P_QGIsCiahRV"}},{"cell_type":"markdown","metadata":{"id":"BvQ_Qq6XReM-"},"source":["Given a list of documents."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"qVulTRHURZuO","executionInfo":{"status":"ok","timestamp":1669826496617,"user_tz":300,"elapsed":334,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"7632767f-a246-4e56-cb13-19f1caa4d819"},"source":["text <-  c(d1 = \"First example, An example of Preprocessing Techniques.\",  \n","           d2 = \"Second example, an Additional Technique example During Lab.\",  \n","           d3 = \"Finaly, a Third Technique Example.\") \n","text "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<style>\n",".dl-inline {width: auto; margin:0; padding: 0}\n",".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n","</style><dl class=dl-inline><dt>d1</dt><dd>'First example, An example of Preprocessing Techniques.'</dd><dt>d2</dt><dd>'Second example, an Additional Technique example During Lab.'</dd><dt>d3</dt><dd>'Finaly, a Third Technique Example.'</dd></dl>\n"],"text/markdown":"d1\n:   'First example, An example of Preprocessing Techniques.'d2\n:   'Second example, an Additional Technique example During Lab.'d3\n:   'Finaly, a Third Technique Example.'\n\n","text/latex":"\\begin{description*}\n\\item[d1] 'First example, An example of Preprocessing Techniques.'\n\\item[d2] 'Second example, an Additional Technique example During Lab.'\n\\item[d3] 'Finaly, a Third Technique Example.'\n\\end{description*}\n","text/plain":["                                                           d1 \n","     \"First example, An example of Preprocessing Techniques.\" \n","                                                           d2 \n","\"Second example, an Additional Technique example During Lab.\" \n","                                                           d3 \n","                         \"Finaly, a Third Technique Example.\" "]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"RcfvJEF6Rvbw"},"source":["**Step 1**\n","\n","Compute the Document-Term Matrix using the `dfm` function.\n","Ensure that the following pre-processing is applied:\n","- **lower case**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"NRtzJCAtcZnQ","executionInfo":{"status":"ok","timestamp":1669827463686,"user_tz":300,"elapsed":178,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"fe46bd8c-35f9-4526-b8ca-10dafddaf247"},"source":["dtm <- tokens(text)\n","dtm <- dfm(# Write your code here)\n","dtm\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Document-feature matrix of: 3 documents, 16 features (50.00% sparse) and 0 docvars.\n","    features\n","docs first example , an of preprocessing techniques . second additional\n","  d1     1       2 1  1  1             1          1 1      0          0\n","  d2     0       2 1  1  0             0          0 1      1          1\n","  d3     0       1 1  0  0             0          0 1      0          0\n","[ reached max_nfeat ... 6 more features ]"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"BgYMdTAuS8Sk"},"source":["**Step 2**\n","\n","Compute the Document-Term Matrix using the `dfm` function.\n","Ensure that the following pre-processing is applied:\n","- lower case;\n","- **stopword removal**. Use the auto-complete to find the proper command, starting with `dfm_`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"CHftsA6XeN7N","executionInfo":{"status":"ok","timestamp":1669827528048,"user_tz":300,"elapsed":227,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"cdf903c5-ff18-4f15-a97b-bf59bc4c1f15"},"source":["dtm <- # Write your code here\n","dtm <- # Write your code here\n","dtm"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Document-feature matrix of: 3 documents, 12 features (47.22% sparse) and 0 docvars.\n","    features\n","docs first example , preprocessing techniques . second additional technique lab\n","  d1     1       2 1             1          1 1      0          0         0   0\n","  d2     0       2 1             0          0 1      1          1         1   1\n","  d3     0       1 1             0          0 1      0          0         1   0\n","[ reached max_nfeat ... 2 more features ]"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"zcYRvx8ESPva"},"source":["**Step 3**\n","\n","Compute the Document-Term Matrix using the `dfm` function.\n","Ensure that the following pre-processing is applied:\n","- lower case;\n","- stopword removal;\n","- **stemming**. Use the auto-complete to find the proper command, starting with `dfm_`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"ZIBQZ41rfgM9","executionInfo":{"status":"ok","timestamp":1669827534163,"user_tz":300,"elapsed":181,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"9fdbfe47-5a36-4500-c91a-02fb5cdce906"},"source":["dtm <- # Write your code here\n","dtm <- # Write your code here\n","dtm <- # Write your code here\n","dtm"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Document-feature matrix of: 3 documents, 11 features (42.42% sparse) and 0 docvars.\n","    features\n","docs first exampl , preprocess techniqu . second addit lab finali\n","  d1     1      2 1          1        1 1      0     0   0      0\n","  d2     0      2 1          0        1 1      1     1   1      0\n","  d3     0      1 1          0        1 1      0     0   0      1\n","[ reached max_nfeat ... 1 more feature ]"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Kf9x2dwQtlbt"},"source":["## Filtering and Weighting - Task 7"]},{"cell_type":"markdown","metadata":{"id":"RfliqCAB1rM6"},"source":["**Step 1 - Calculate Document Frequency**\n","\n","Calculate the Document Frequency per Term. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyYJAtfdsDII","executionInfo":{"status":"ok","timestamp":1669827550411,"user_tz":300,"elapsed":179,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"bfcc6d1e-0c82-4b50-eba5-e4398276c80a"},"source":[" doc_freq <- # Write your code here\n"," print(doc_freq)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     first     exampl preprocess   techniqu     second      addit        lab \n","         1          3          1          3          1          1          1 \n","    finali      third \n","         1          1 \n"]}]},{"cell_type":"markdown","metadata":{"id":"XeUgNvwD1QJh"},"source":["**Step 2 - Filtering**\n","\n","Use the document frequency to select terms with *frequency* >= 2."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"R1ZtTBZzsXLj","executionInfo":{"status":"ok","timestamp":1669827560637,"user_tz":300,"elapsed":148,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"ad4cdc69-625d-4618-e705-6ca2aa6179c0"},"source":["\n","dtm2 <- dtm[# Write your code here]\n","dtm2"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Document-feature matrix of: 3 documents, 2 features (0.00% sparse) and 0 docvars.\n","    features\n","docs exampl techniqu\n","  d1      2        1\n","  d2      2        1\n","  d3      1        1"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"5x-HBpXx0c3Y"},"source":["**Weighting Terms with TF-IDF**"]},{"cell_type":"markdown","metadata":{"id":"QeJ0uQ5W2Opr"},"source":["**Step 3 - Weighting**\n","\n","Calculate the *frequency-inverse document frequency (tf-idf)* of the corpus.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"id":"Hl4f-2nHswPL","executionInfo":{"status":"ok","timestamp":1669827587870,"user_tz":300,"elapsed":150,"user":{"displayName":"Siavash Hosseini","userId":"05262157102912941127"}},"outputId":"2970f67e-6200-4b45-b152-96adf1675b28"},"source":["dtm3 <- dfm_tfidf(dtm)\n","dtm3"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Document-feature matrix of: 3 documents, 9 features (51.85% sparse) and 0 docvars.\n","    features\n","docs     first exampl preprocess techniqu    second     addit       lab\n","  d1 0.4771213      0  0.4771213        0 0         0         0        \n","  d2 0              0  0                0 0.4771213 0.4771213 0.4771213\n","  d3 0              0  0                0 0         0         0        \n","    features\n","docs    finali     third\n","  d1 0         0        \n","  d2 0         0        \n","  d3 0.4771213 0.4771213"]},"metadata":{}}]}]}